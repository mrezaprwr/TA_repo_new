{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "import math\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Text Library\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Splitting Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import libary for TFID Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Import feature selection Libraries\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression, mutual_info_classif\n",
    "\n",
    "# Algorithm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Functions and Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "def import_data(folder, fileName):\n",
    "    return pd.read_csv(folder+fileName+'.csv', index_col=0)\n",
    "# Export dataset\n",
    "def export_data(dataset, fileName):\n",
    "    return dataset.to_csv(fileName+'.csv')\n",
    "\n",
    "# Generate vectors from train and test dataset\n",
    "def generate_vec(train_data, test_data):\n",
    "    X_train = train_data['text'].values\n",
    "    y_train = train_data['label'].values\n",
    "\n",
    "    X_test = test_data['text'].values\n",
    "    y_test = test_data['label'].values\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=1.0, min_df=1, lowercase = False, stop_words=None)\n",
    "\n",
    "    # Fit transform to data train\n",
    "    tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    # return list of train and test vectors\n",
    "    return [tfidf_train, tfidf_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder location of Dataset\n",
    "folder = 'C:/Users/ASUS/Documents/Learn Data Science/train_test/'\n",
    "ft_folder = 'C:/Users/ASUS/Documents/Learn Data Science/tfidf_features/'\n",
    "\n",
    "# Import df_pre2\n",
    "train_pre2 = import_data(folder, 'pre2/train_pre2')\n",
    "test_pre2 = import_data(folder, 'pre2/test_pre2')\n",
    "\n",
    "# Import feature dataset of pre1 dan pre2\n",
    "fitur_pre1 = import_data(ft_folder, 'pre1/fitur_pre1')\n",
    "fitur_pre2 = import_data(ft_folder, 'pre2/fitur_pre2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Get each train and test values of every dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre2 = train_pre2['text'].values\n",
    "y_train_pre2 = train_pre2['label'].values\n",
    "\n",
    "X_test_pre2 = test_pre2['text'].values\n",
    "y_test_pre2 = test_pre2['label'].values\n",
    "\n",
    "# Generate feature vector for each dataset\n",
    "vec_data = generate_vec(train_pre2, test_pre2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features length of train data: 3376\n"
     ]
    }
   ],
   "source": [
    "# Show train vectors of each dataset / how many features\n",
    "print(\"Features length of train data:\",vec_data[0].shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>-- Build feature extraction vectorizer -- </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature train and test for df_pre2\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=1.0, min_df=1, lowercase = False, stop_words=None)\n",
    "\n",
    "# Fit transform to data train\n",
    "tfidf_train_pre2 = tfidf_vectorizer.fit_transform(X_train_pre2)\n",
    "tfidf_test_pre2 = tfidf_vectorizer.transform(X_test_pre2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> -- Create feature matrix for train & test df_pre2 -- </strong> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataframe based on matrix train_pre2\n",
    "train_pre2_mtx = pd.DataFrame(data=tfidf_train_pre2.toarray(),columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "# Build a dataframe based on matrix test_pre2\n",
    "test_pre2_mtx = pd.DataFrame(data=tfidf_test_pre2.toarray(),columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abort</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abuse</th>\n",
       "      <th>abused</th>\n",
       "      <th>...</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yoyo</th>\n",
       "      <th>yukata</th>\n",
       "      <th>yum</th>\n",
       "      <th>zero</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zoloft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandoned  abandonment  ability  able  abort  absent  absolute  absolutely  \\\n",
       "0        0.0          0.0      0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "1        0.0          0.0      0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "2        0.0          0.0      0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "\n",
       "   abuse  abused  ...  youll  young  youre  youtube  yoyo  yukata  yum  zero  \\\n",
       "0    0.0     0.0  ...    0.0    0.0    0.0      0.0   0.0     0.0  0.0   0.0   \n",
       "1    0.0     0.0  ...    0.0    0.0    0.0      0.0   0.0     0.0  0.0   0.0   \n",
       "2    0.0     0.0  ...    0.0    0.0    0.0      0.0   0.0     0.0  0.0   0.0   \n",
       "\n",
       "   zipped  zoloft  \n",
       "0     0.0     0.0  \n",
       "1     0.0     0.0  \n",
       "2     0.0     0.0  \n",
       "\n",
       "[3 rows x 3376 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pre2_mtx.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics\n",
      "Akurasi df_pre2: 82.23\n",
      "Precision df_pre2: 75.18\n",
      "Recall df_pre2: 100.0\n",
      "F1 Score df_pre2: 85.83\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnbTfidf = mnb.fit(tfidf_train_pre2, y_train_pre2) # training the model\n",
    "predictTfidf = mnbTfidf.predict(tfidf_test_pre2)\n",
    "\n",
    "print(\"Evaluation Metrics\")\n",
    "print(\"Akurasi df_pre2:\", round(accuracy_score(y_test_pre2,predictTfidf)*100, 2))\n",
    "print(\"Precision df_pre2:\", round(precision_score(y_test_pre2, predictTfidf)*100, 2))\n",
    "print(\"Recall df_pre2:\", round(recall_score(y_test_pre2, predictTfidf)*100,2))\n",
    "print(\"F1 Score df_pre2:\", round(f1_score(y_test_pre2, predictTfidf)*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection with Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Find feature length variation from 100% to 10%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100%', '90%', '80%', '70%', '60%', '50%', '40%', '30%', '20%', '10%']\n",
      "Variasi jumlah fitur pre2: [3376, 3038, 2701, 2363, 2026, 1688, 1350, 1013, 675, 338]\n"
     ]
    }
   ],
   "source": [
    "format_jml_ft = [\"{}%\".format(x*10) for x in range(10,0,-1)]\n",
    "# length variation for df_pre2\n",
    "lenFitur_pre2 = sorted([round(x*0.1*tfidf_train_pre2.shape[1]) for x in range(1, 11)], reverse=True)\n",
    "print(format_jml_ft)\n",
    "print(\"Variasi jumlah fitur pre2:\", lenFitur_pre2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--  Add train labels from each train dataset to the respective train matrix --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign each train label dataset to each respective train matrix\n",
    "train_pre2_mtx['label_value'] = y_train_pre2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Run Function --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fund entropy of target cols / label of dataset\n",
    "def entropy(target_col):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a dataset.\n",
    "    The only parameter of this function is the target_col parameter which specifies the target column\n",
    "    \"\"\"\n",
    "    elements,counts = np.unique(target_col,return_counts = True)\n",
    "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "    return entropy\n",
    "\n",
    "# Function to find Information Gain value of a feature/attribute\n",
    "def InfoGain(data,split_attribute_name,target_name=\"class\"):\n",
    "    \"\"\"\n",
    "    Calculate the information gain of a dataset. This function takes three parameters:\n",
    "    1. data = The dataset for whose feature the IG should be calculated\n",
    "    2. split_attribute_name = the name of the feature for which the information gain should be calculated\n",
    "    3. target_name = the name of the target feature. The default for this example is \"class\"\n",
    "    \"\"\"    \n",
    "    #Calculate the entropy of the total dataset\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    \n",
    "    ##Calculate the entropy of the dataset\n",
    "    \n",
    "    #Calculate the values and the corresponding counts for the split attribute \n",
    "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
    "    \n",
    "    #Calculate the weighted entropy\n",
    "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i])\\\n",
    "                                                                  .dropna()[target_name]) for i in range(len(vals))])\n",
    "    \n",
    "    #Calculate the information gain\n",
    "    Information_Gain = total_entropy - Weighted_Entropy\n",
    "    return Information_Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>-- Find IG value of each feature dataset --</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find IG for each feature\n",
    "# ig_pre2_arr, time_c_arr, clock_c_arr = [], [], []\n",
    "# listFitur_pre2 = list(fitur_pre2.feature)\n",
    "\n",
    "# # Iterate through each df_pre2 feature to find IG value\n",
    "# # Starting time\n",
    "# clock_start = time.clock()\n",
    "# time_start = time.time()\n",
    "# for i in range(len(listFitur_pre2)):\n",
    "#     print('Fitur ke-',i)\n",
    "#     clock_s = time.clock()\n",
    "#     time_s = time.time()\n",
    "#     ig_pre2_arr.append(InfoGain(train_pre2_mtx, listFitur_pre2[i], 'label_value'))\n",
    "#     # Append individual time\n",
    "#     clock_c_arr.append(time.clock() - clock_s)\n",
    "#     time_c_arr.append(time.time() - time_s)\n",
    "\n",
    "# tot_clock = time.clock() - clock_start\n",
    "# tot_time = time.time() - time_start\n",
    "# # Insert ig_value to dataframe\n",
    "# fitur_pre2['ig_value'] = ig_pre2_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Computation time for each feature\n",
    "# print(pd.Series(time_c_arr).describe())\n",
    "# print(\"Total computation time for All information Gain:\", str(round(sum(time_c_arr)/60, 2)) + \" minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Export feature dataframe that contains ig_value in it</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export fitur_pre1 with ig_value\n",
    "# export_data(fitur_pre2, 'fitur_pre2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'C:/Users/ASUS/Documents/Learn Data Science/all_dataset/IG_features/'\n",
    "\n",
    "fitur_pre2 = import_data(loc, 'fitur_pre2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>mi_value</th>\n",
       "      <th>df_dep</th>\n",
       "      <th>df_nonDep</th>\n",
       "      <th>cpd</th>\n",
       "      <th>ig_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>abandonment</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ability</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  tfidf  mi_value  df_dep  df_nonDep  cpd  ig_value\n",
       "0    abandoned    0.0  0.001439       1          0  1.0  0.002076\n",
       "1  abandonment    0.0  0.001439       1          0  1.0  0.002076\n",
       "2      ability    0.0  0.001439       1          0  1.0  0.002076"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataframe df_pre1 with ig_value\n",
    "fitur_pre2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>-- Tuning parameter Information Gain --</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort each feature dataframe based on ig_value\n",
    "fitur_pre2_sorted = fitur_pre2.sort_values(by='ig_value', ascending=False)\n",
    "fitur_pre2_sorted = list(fitur_pre2_sorted.feature) # convert ig columns into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like', 'feel', 'get', 'im', 'happy', 'know', 'really', 'got', 'life', 'year']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitur_pre2_sorted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Find accuracy for each subset feature selected by Information Gain --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for df_pre2\n",
    "acc_ig_pre2, prec_ig_pre2, rec_ig_pre2, f1score_ig_pre2 = ([] for i in range (4))\n",
    "clock_arr_ig, time_arr_ig = [], []\n",
    "\n",
    "for i in range(len(lenFitur_pre2)):\n",
    "    # Create subset feature based on top-n lenFitur\n",
    "    subset_feature = fitur_pre2_sorted[:lenFitur_pre2[i]]\n",
    "    \n",
    "    # Create feature matrix for train and test\n",
    "    features_train = scipy.sparse.csr_matrix(train_pre2_mtx[subset_feature].values)\n",
    "    features_test = scipy.sparse.csr_matrix(test_pre2_mtx[subset_feature].values)\n",
    "    \n",
    "    time_s, clock_s = time.time(), time.clock()\n",
    "    # Build models and fit to train vector\n",
    "    mnb = MultinomialNB()\n",
    "    mnbTfidf = mnb.fit(features_train, y_train_pre2) # training the model\n",
    "    predictTfidf = mnbTfidf.predict(features_test)\n",
    "    clock_arr_ig.append(time.clock() - clock_s)\n",
    "    time_arr_ig.append(time.time() - time_s)\n",
    "    \n",
    "    # Append accuracy, precision, recall, f1score for each feature selection \n",
    "    acc_ig_pre2.append(accuracy_score(y_test_pre2,predictTfidf))\n",
    "    prec_ig_pre2.append(precision_score(y_test_pre2, predictTfidf))\n",
    "    rec_ig_pre2.append(recall_score(y_test_pre2, predictTfidf))\n",
    "    f1score_ig_pre2.append(f1_score(y_test_pre2, predictTfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Show list of accuracy from IG --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Jumlah fitur (%): ['100%', '90%', '80%', '70%', '60%', '50%', '40%', '30%', '20%', '10%'] \n",
      "\n",
      "Accuracy of df_pre2 (%): [82.23, 81.22, 80.2, 79.7, 80.2, 85.28, 87.82, 86.8, 86.8, 87.31]\n",
      "Precision of df_pre2 (%): [75.18, 74.13, 73.1, 72.6, 73.1, 78.52, 82.03, 82.26, 83.33, 84.03]\n",
      "Recall of df_pre2 (%): [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.06, 96.23, 94.34, 94.34]\n",
      "F1 Score of df_pre2 (%): [85.83, 85.14, 84.46, 84.13, 84.46, 87.97, 89.74, 88.7, 88.5, 88.89]\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall & f1_score of df_pre2\n",
    "print(\"Format Jumlah fitur (%):\", [\"{}%\".format(x*10) for x in range(10,0,-1)], \"\\n\")\n",
    "print(\"Accuracy of df_pre2 (%):\", [(round(x*100,2)) for x in acc_ig_pre2])\n",
    "print(\"Precision of df_pre2 (%):\", [(round(x*100,2)) for x in prec_ig_pre2])\n",
    "print(\"Recall of df_pre2 (%):\", [(round(x*100,2)) for x in rec_ig_pre2])\n",
    "print(\"F1 Score of df_pre2 (%):\", [(round(x*100,2)) for x in f1score_ig_pre2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy: 87.82 dgn jumlah fitur: 40%\n",
      "Maximum Precision: 84.03 dgn jumlah fitur: 10%\n",
      "Maximum Recall: 100.0 dgn jumlah fitur: 100%\n",
      "Maximum F1_Score : 89.74 dgn jumlah fitur: 40%\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum accuracy:\", round(max(acc_ig_pre2)*100, 2), \"dgn jumlah fitur:\", \\\n",
    "      format_jml_ft[acc_ig_pre2.index(max(acc_ig_pre2))])\n",
    "\n",
    "print(\"Maximum Precision:\", round(max(prec_ig_pre2)*100, 2), \"dgn jumlah fitur:\", \\\n",
    "      format_jml_ft[prec_ig_pre2.index(max(prec_ig_pre2))])\n",
    "\n",
    "print(\"Maximum Recall:\", round(max(rec_ig_pre2)*100, 2), \"dgn jumlah fitur:\", \\\n",
    "      format_jml_ft[rec_ig_pre2.index(max(rec_ig_pre2))])\n",
    "\n",
    "print(\"Maximum F1_Score :\", round(max(f1score_ig_pre2)*100, 2), \"dgn jumlah fitur:\", \\\n",
    "      format_jml_ft[f1score_ig_pre2.index(max(f1score_ig_pre2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection with CPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Create dataframe that contains document frequency --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate document frequency of each feature in train data\n",
    "# Input: word, train dataframe\n",
    "def find_df(feature, train_data):\n",
    "    tok_train = train_data.text.apply(lambda x: str(x).split())\n",
    "    df_arr = []\n",
    "    for i in range(0, len(feature)):\n",
    "        freq = 0\n",
    "        for item in tok_train:\n",
    "            # if feature exist in data\n",
    "          if feature[i] in item:\n",
    "            freq += 1\n",
    "        df_arr.append(freq)\n",
    "    return df_arr\n",
    "\n",
    "# Find CPD Value of each feature\n",
    "# Input: word, list of document frequency for dep and non-dep; Output: cpd value & computation time\n",
    "def find_cpd_value(feature, arr_dep, arr_nonDep):\n",
    "    clock_arr, time_arr, cpd = [], [], []\n",
    "    for i in range (0, len(feature)):\n",
    "        time_s = time.time()\n",
    "        clock_s = time.clock()\n",
    "        \n",
    "        val = abs(arr_dep[i] - arr_nonDep[i])/(arr_dep[i] + arr_nonDep[i])\n",
    "        time_arr.append(time.time() - time_s)\n",
    "        clock_arr.append(time.clock() - clock_s)\n",
    "        cpd.append(val)\n",
    "    return [cpd, time_arr, clock_arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Find depression and non-depression document frequency of each feature dataset --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split depression and non-depression data from each train data\n",
    "train_pre2_dep = train_pre2[train_pre2.label == 1]\n",
    "train_pre2_nonDep = train_pre2[train_pre2.label == 0]\n",
    "\n",
    "# Find depression and non-depression document frequency of each features from df_pre2\n",
    "df_dep_pre2 = find_df(list(fitur_pre2.feature), train_pre2_dep)\n",
    "df_nonDep_pre2 = find_df(list(fitur_pre2.feature), train_pre2_nonDep)\n",
    "\n",
    "# Create new columns (document frequency based on labels in feature dataset)\n",
    "fitur_pre2['df_dep'] = df_dep_pre2\n",
    "fitur_pre2['df_nonDep'] = df_nonDep_pre2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_dep</th>\n",
       "      <th>df_nonDep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   df_dep  df_nonDep\n",
       "0       1          0\n",
       "1       1          0\n",
       "2       1          0\n",
       "3       7          9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitur_pre2[['df_dep', 'df_nonDep']].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Generate CPD value for each feature --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "# CPD of pre2\n",
    "cpd_values = find_cpd_value(list(fitur_pre2.feature), df_dep_pre2, df_nonDep_pre2)\n",
    "cpd = cpd_values[0]\n",
    "time_arr = cpd_values[1]\n",
    "clock_arr = cpd_values[1]\n",
    "\n",
    "fitur_pre2['cpd'] = cpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3376.000000\n",
       "mean        0.000003\n",
       "std         0.000057\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         0.001003\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(clock_arr).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010974407196044922"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(clock_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3376, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitur_pre2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>mi_value</th>\n",
       "      <th>df_dep</th>\n",
       "      <th>df_nonDep</th>\n",
       "      <th>cpd</th>\n",
       "      <th>ig_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3087</td>\n",
       "      <td>truth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3002</td>\n",
       "      <td>though</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014889</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.021480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>guys</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011854</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.017101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1446</td>\n",
       "      <td>hours</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020841</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.030067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3103</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  tfidf  mi_value  df_dep  df_nonDep       cpd  ig_value\n",
       "3087    truth    0.0  0.005783       4          0  1.000000  0.008343\n",
       "3002   though    0.0  0.014889       7          3  0.400000  0.021480\n",
       "1304     guys    0.0  0.011854       6          2  0.500000  0.017101\n",
       "1446    hours    0.0  0.020841      10          4  0.428571  0.030067\n",
       "3103  twitter    0.0  0.001602       0          1  1.000000  0.002312"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of feature in df_pre1\n",
    "fitur_pre2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution for CPD in pre1 & pre2\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
    "fitur_pre2.ig_value.hist(ax=axes[0])\n",
    "fitur_pre2.cpd.hist(ax=axes[1])\n",
    "axes[0].title.set_text('IG Distribution')\n",
    "axes[1].title.set_text('CPD Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export features with cpd value\n",
    "# export_data(fitur_pre2, 'fitur_pre2_cpd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Get subset feature with CPD Parameter Tuning --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list that contains value from 0.1 to 1\n",
    "frac_val = [i/10 for i in range(1,11)]\n",
    "\n",
    "# Initiate empty list to take each feature subset selected by cpd tuning\n",
    "cpd_ft_pre2 = [] # df_pre2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in frac_val:\n",
    "    # CPD Tuning for df_pre2\n",
    "    cpd_ft_pre2.append(list(fitur_pre2[(fitur_pre2['cpd'] > 0) & (fitur_pre2['cpd'] <= item)].feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3376, 3038, 2701, 2363, 2026, 1688, 1350, 1013, 675, 338]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenFitur_pre2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 83, 113, 287, 396, 475, 526, 586, 603, 3166]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in cpd_ft_pre2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Slice feature dataframe based on subset feature by CPD  --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice df_pre1 feature based on subset from both CPD selection\n",
    "# fitur_pre2_cpd = []\n",
    "\n",
    "# # Iterate through both cpd parameter tuning and append to list\n",
    "# for i in range (len(cpd_ft_pre1)):\n",
    "#     fitur_pre2_cpd.append(fitur_pre2[fitur_pre2.feature.isin(cpd_ft_pre2[i])])\n",
    "\n",
    "# # Slice df_pre2 feature based on subset from both CPD selection\n",
    "# fitur_pre2_cpd = []\n",
    "\n",
    "# # Iterate through both cpd parameter tuning and append to list\n",
    "# for i in range (len(cpd_ft_pre2)):\n",
    "#     fitur_pre2_cpd.append(fitur_pre2[fitur_pre2.feature.isin(cpd_f2_pre2[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Export subset feature dataframe based on CPD tuning parameter</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of number from 1-10 to append in the end of file name\n",
    "# idx_export = [int(x*10) for x in frac_val]\n",
    "\n",
    "# # Iterate to export all feature dataframe based on CPD tuning parameter of df_pre1\n",
    "# for i in range(0, len(fitur_pre1_cpd1)):\n",
    "#     # Appended file name\n",
    "#     tuning_1 = 'fitur_pre1_cpd1_'\n",
    "#     tuning_2 = 'fitur_pre1_cpd2_'\n",
    "#     # Export df_pre1 feature dataframe with defined function\n",
    "#     export_data(fitur_pre1_cpd1[i], tuning_1+str(idx_export[i]))\n",
    "#     export_data(fitur_pre1_cpd2[i], tuning_2+str(idx_export[i]))\n",
    "    \n",
    "# # Iterate to export all feature dataframe based on CPD tuning parameter of df_pre2\n",
    "# for i in range(0, len(fitur_pre2_cpd1)):\n",
    "#     # Appended file name\n",
    "#     tuning_1 = 'fitur_pre2_cpd1_'\n",
    "#     tuning_2 = 'fitur_pre2_cpd2_'\n",
    "#     # Export df_pre2 feature dataframe with defined function\n",
    "#     export_data(fitur_pre2_cpd1[i], tuning_1+str(idx_export[i]))\n",
    "#     export_data(fitur_pre2_cpd2[i], tuning_2+str(idx_export[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Accuracy of cpd subset --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Get Accuracy of each subset cpd features \n",
    "acc_cpd_pre2, prec_cpd_pre2, rec_cpd_pre2, f1score_cpd_pre2 = ([] for i in range(4))\n",
    "time_arr_cpd, clock_arr_cpd = [], []\n",
    "\n",
    "for i in range (len(cpd_ft_pre2)):\n",
    "    features_train = scipy.sparse.csr_matrix(train_pre2_mtx[cpd_ft_pre2[i]].values)\n",
    "    features_test = scipy.sparse.csr_matrix(test_pre2_mtx[cpd_ft_pre2[i]].values)\n",
    "    \n",
    "    mnb = MultinomialNB()\n",
    "    time_s, clock_s = time.time(), time.clock()\n",
    "    mnbTfidf = mnb.fit(features_train, y_train_pre2) # training the model\n",
    "    predictTfidf = mnbTfidf.predict(features_test)\n",
    "    time_arr_cpd.append(time.time()-time_s)\n",
    "    clock_arr_cpd.append(time.clock()-clock_s)\n",
    "    \n",
    "    acc_cpd_pre2.append(accuracy_score(y_test_pre2,predictTfidf))\n",
    "    prec_cpd_pre2.append(precision_score(y_test_pre2, predictTfidf))\n",
    "    rec_cpd_pre2.append(recall_score(y_test_pre2, predictTfidf))\n",
    "    f1score_cpd_pre2.append(f1_score(y_test_pre2, predictTfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.002001047134399414,\n",
       " 0.004984855651855469,\n",
       " 0.0020003318786621094,\n",
       " 0.0019989013671875,\n",
       " 0.0019996166229248047,\n",
       " 0.002996683120727539,\n",
       " 0.0030007362365722656,\n",
       " 0.0019989013671875,\n",
       " 0.0020003318786621094,\n",
       " 0.001999378204345703]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_arr_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Jumlah fitur (%): ['<=0.1', '<=0.2', '<=0.3', '<=0.4', '<=0.5', '<=0.6', '<=0.7', '<=0.8', '<=0.9', '<=1.0'] \n",
      "\n",
      "Accuracy of df_pre2 (%): [54.31, 61.42, 61.93, 68.53, 70.56, 74.62, 78.68, 84.26, 84.26, 80.2]\n",
      "Precision of df_pre2 (%): [54.08, 59.15, 60.4, 65.94, 67.65, 70.0, 73.53, 79.53, 79.53, 73.1]\n",
      "Recall of df_pre2 (%): [100.0, 91.51, 84.91, 85.85, 86.79, 92.45, 94.34, 95.28, 95.28, 100.0]\n",
      "F1 Score of df_pre2 (%): [70.2, 71.85, 70.59, 74.59, 76.03, 79.67, 82.64, 86.7, 86.7, 84.46]\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall & f1_score of df_pre2\n",
    "format_ft_cpd = ['<='+str(round(x*0.1,2)) for x in range(1,11)]\n",
    "print(\"Format Jumlah fitur (%):\", format_ft_cpd, \"\\n\")\n",
    "print(\"Accuracy of df_pre2 (%):\", [(round(x*100,2)) for x in acc_cpd_pre2])\n",
    "print(\"Precision of df_pre2 (%):\", [(round(x*100,2)) for x in prec_cpd_pre2])\n",
    "print(\"Recall of df_pre2 (%):\", [(round(x*100,2)) for x in rec_cpd_pre2])\n",
    "print(\"F1 Score of df_pre2 (%):\", [(round(x*100,2)) for x in f1score_cpd_pre2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Analyze feature subset with CPD from each dataset for tuning -2--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_cpd_pre1 = import_data(loc, 'df_pre1/Parameter 2/fitur_pre1_cpd2_9')\n",
    "# print(\"Banyak fitur cpd-pre1: \", len(cpd_pre1))\n",
    "loc = 'C:/Users/ASUS/Documents/Learn Data Science/all_dataset/cpd_features/'\n",
    "subset_cpd_pre2 = import_data(loc, 'df_pre2/Parameter 2/fitur_pre2_cpd2_9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze subset features from both feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature from stemmed data\n",
    "loc = 'C:/Users/ASUS/Documents/Learn Data Science/all_dataset/tfidf_features/'\n",
    "\n",
    "stem_pre1 = import_data(loc, 'pre1_stemmed/fitur_pre1_stemmed')\n",
    "stem_pre2 = import_data(loc, 'pre2_stemmed/fitur_pre2_stemmed')\n",
    "\n",
    "stemmed_pre1 = [x for x in list(fitur_pre1.feature) if x not in list(stem_pre1.feature)]\n",
    "stemmed_pre2 = [x for x in list(fitur_pre2.feature) if x not in list(stem_pre2.feature)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find non-ig-subset \n",
    "# non_subset_ig_pre1 = [x for x in list(fitur_pre1.feature) if x not in subset_ig_pre1]\n",
    "# non_subset_ig_pre2 = [x for x in list(fitur_pre2.feature) if x not in subset_ig_pre2]\n",
    "\n",
    "# # Find non-cpd-subset \n",
    "# non_subset_cpd_pre1 = [x for x in list(fitur_pre1.feature) if x not in list(subset_cpd_pre1.feature)]\n",
    "# non_subset_cpd_pre2 = [x for x in list(fitur_pre2.feature) if x not in list(subset_cpd_pre2.feature)]\n",
    "\n",
    "# # Find sw in df_pre1\n",
    "# sw_subs_ig_pre1 = [x for x in subset_ig_pre1 if x in list(stop_words)]\n",
    "# sw_nonsubs_ig_pre1 = [x for x in non_subset_ig_pre1 if x in list(stop_words)]\n",
    "\n",
    "# sw_subs_cpd_pre1 = [x for x in list(subset_cpd_pre1.feature) if x in list(stop_words)]\n",
    "# sw_nonsubs_cpd_pre1 = [x for x in non_subset_cpd_pre1 if x in list(stop_words)]\n",
    "\n",
    "# # Find stemmed in df_pre1\n",
    "# stemmed_subs_ig_pre1 = [x for x in subset_ig_pre1 if x in stemmed_pre1]\n",
    "# stemmed_nonsubs_ig_pre1 = [x for x in non_subset_ig_pre1 if x in stemmed_pre1]\n",
    "\n",
    "# stemmed_subs_cpd_pre1 = [x for x in list(subset_cpd_pre1.feature) if x in stemmed_pre1]\n",
    "# stemmed_nonsubs_cpd_pre1 = [x for x in non_subset_cpd_pre1 if x in stemmed_pre1]\n",
    "\n",
    "# # Find stemmed in df_pre2\n",
    "# stemmed_subs_ig_pre2 = [x for x in subset_ig_pre2 if x in stemmed_pre2]\n",
    "# stemmed_nonsubs_ig_pre2 = [x for x in non_subset_ig_pre2 if x in stemmed_pre2]\n",
    "\n",
    "# stemmed_subs_cpd_pre2 = [x for x in list(subset_cpd_pre2.feature) if x in stemmed_pre2]\n",
    "# stemmed_nonsubs_cpd_pre2 = [x for x in non_subset_cpd_pre2 if x in stemmed_pre2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dfPre1\n",
    "# print('dfpre1\\n')\n",
    "# print(\"Count of sw in ig-subset df_pre1:\",len(sw_subs_ig_pre1))\n",
    "# print(\"Count of sw in ig-nonsubset df_pre1:\",len(sw_nonsubs_ig_pre1))\n",
    "\n",
    "# print(\"Count of sw in cpd-subset df_pre1:\",len(sw_subs_cpd_pre1))\n",
    "# print(\"Count of sw in cpd-nonsubset df_pre1:\",len(sw_nonsubs_cpd_pre1))\n",
    "# print('\\n')\n",
    "# print(\"Count of stemmed in ig-subset df_pre1:\",len(stemmed_subs_ig_pre1))\n",
    "# print(\"Count of stemmed in ig-nonsubset df_pre1:\",len(stemmed_nonsubs_ig_pre1))\n",
    "\n",
    "# print(\"Count of stemmed in cpd-subset df_pre1:\",len(stemmed_subs_cpd_pre1))\n",
    "# print(\"Count of stemmed in cpd-nonsubset df_pre1:\",len(stemmed_nonsubs_cpd_pre1))\n",
    "\n",
    "# # dfPre2\n",
    "# print('\\ndfpre2\\n')\n",
    "# print(\"Count of stemmed in ig-subset df_pre2:\",len(stemmed_subs_ig_pre2))\n",
    "# print(\"Count of stemmed in ig-nonsubset df_pre2:\",len(stemmed_nonsubs_ig_pre2))\n",
    "\n",
    "# print(\"Count of stemmed in cpd-subset df_pre2:\",len(stemmed_subs_cpd_pre2))\n",
    "# print(\"Count of stemmed in cpd-nonsubset df_pre2:\",len(stemmed_nonsubs_cpd_pre2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
