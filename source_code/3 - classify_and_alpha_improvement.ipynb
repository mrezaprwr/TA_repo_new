{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "import math\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Text Library\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Splitting Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import libary for TFID Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Import feature selection Libraries\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression, mutual_info_classif\n",
    "\n",
    "# Algorithm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Run Functions --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "def import_data(folder, fileName):\n",
    "    return pd.read_csv(folder+fileName+'.csv', index_col=0)\n",
    "# Export dataset\n",
    "def export_data(dataset, fileName):\n",
    "    return dataset.to_csv(fileName+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify data based on train and test with alpha value\n",
    "def classify_data(train_data, test_data, alpha_value=0):\n",
    "    # Separate text and label data for train and test\n",
    "    X_train = train_data['text'].values\n",
    "    y_train = train_data['label'].values\n",
    "\n",
    "    X_test = test_data['text'].values\n",
    "    y_test = test_data['label'].values\n",
    "\n",
    "    # TFIDF vectorizer \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=1.0, min_df=1, lowercase = False, stop_words=None)\n",
    "\n",
    "    # Fit transform tfidf_vector to train and test data\n",
    "    tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    # Call model from lib based on alpha_value\n",
    "    if alpha_value == 0:\n",
    "        mnb = MultinomialNB()\n",
    "    else:\n",
    "        mnb = MultinomialNB(alpha=alpha_value)\n",
    "        \n",
    "    # training the model to train and test vector\n",
    "    time_s, clock_s = time.time(), time.clock()\n",
    "    mnbTfidf = mnb.fit(tfidf_train, y_train) \n",
    "    predictTfidf = mnbTfidf.predict(tfidf_test)\n",
    "    time_run = time.time() - time_s\n",
    "    clock_run = time.clock() - clock_s\n",
    "    \n",
    "    # return array containing test data and predicted labels\n",
    "    return [X_test, y_test, predictTfidf, [time_run, clock_run]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get right and wrong classified results data\n",
    "def classified_results(X_test, y_test, predictLabels):\n",
    "    # Initialize lists for right and wrong data\n",
    "    wrongText, wrongLabel = [], []\n",
    "    rightText, rightLabel = [], []\n",
    "    \n",
    "    # iterate through redicted labels and add to initialized lists\n",
    "    for i in range(0,len(predictLabels)):\n",
    "        if(predictLabels[i] != y_test[i]):\n",
    "          wrongText.append(X_test[i])\n",
    "          wrongLabel.append(y_test[i])\n",
    "        else:\n",
    "          rightText.append(X_test[i])\n",
    "          rightLabel.append(y_test[i])\n",
    "    # Create dataframe from appended lists\n",
    "    dfWrong = pd.DataFrame(\n",
    "      {'text': wrongText,\n",
    "      'label': wrongLabel\n",
    "      })\n",
    "\n",
    "    dfRight = pd.DataFrame(\n",
    "      {'text': rightText,\n",
    "      'label': rightLabel\n",
    "      })\n",
    "    # Return right and wrong classified dataframe\n",
    "    return [dfRight, dfWrong]\n",
    "\n",
    "# Find accuracy of predicted data\n",
    "def find_evaluation(y_test, predictTfidf):\n",
    "    return [accuracy_score(y_test,predictTfidf), f1_score(y_test, predictTfidf), recall_score(y_test, predictTfidf)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Semua Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder location of dataset\n",
    "folder = 'C:/Users/ASUS/Documents/Learn Data Science/train_test/'\n",
    "\n",
    "# dataset df_pre1\n",
    "train_pre1 = import_data(folder, 'pre1/train_pre1')\n",
    "test_pre1 = import_data(folder, 'pre1/test_pre1')\n",
    "\n",
    "# dataset df_pre2\n",
    "train_pre2 = import_data(folder, 'pre2/train_pre2')\n",
    "test_pre2 = import_data(folder, 'pre2/test_pre2')\n",
    "\n",
    "# === Stemmed and Lemma dataset ===\n",
    "\n",
    "# dataset df_pre1_stemmed\n",
    "train_pre1_stemmed = import_data(folder, 'pre1_stemmed/train_pre1_stemmed')\n",
    "test_pre1_stemmed = import_data(folder, 'pre1_stemmed/test_pre1_stemmed')\n",
    "\n",
    "# dataset df_pre1_lemma\n",
    "train_pre1_lemma = import_data(folder, 'pre1_lemma/train_pre1_lemma')\n",
    "test_pre1_lemma = import_data(folder, 'pre1_lemma/test_pre1_lemma')\n",
    "\n",
    "# dataset df_pre2_stemmed\n",
    "train_pre2_stemmed = import_data(folder, 'pre2_stemmed/train_pre2_stemmed')\n",
    "test_pre2_stemmed = import_data(folder, 'pre2_stemmed/test_pre2_stemmed')\n",
    "\n",
    "# dataset df_pre2_lemma\n",
    "train_pre2_lemma = import_data(folder, 'pre2_lemma/train_pre2_lemma')\n",
    "test_pre2_lemma = import_data(folder, 'pre2_lemma/test_pre2_lemma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify each dataset and Find Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Variable info:</h4><br>\n",
    "1. predList_ = Get predicted data<br>\n",
    "2. eval_ = Get Evaluation score [Accuracy, Recall] of data\n",
    "\n",
    "train_test_list = a list of lists that contain train and test data<br>\n",
    "train-> index 0; test-> index 1;<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs_pre1 = classified_results(predList_pre1[0], predList_pre1[1], predList_pre1[2])\n",
    "# rs_pre2 = classified_results(predList_pre2[0], predList_pre2[1], predList_pre2[2])\n",
    "# rs_pre1_stemmed = classified_results(predList_pre1_stemmed[0], predList_pre1_stemmed[1], predList_pre1_stemmed[2])\n",
    "# rs_pre1_lemma = classified_results(predList_pre1_lemma[0], predList_pre1_lemma[1], predList_pre1_lemma[2])\n",
    "# rs_pre2_stemmed = classified_results(predList_pre2_stemmed[0], predList_pre2_stemmed[1], predList_pre2_stemmed[2])\n",
    "# rs_pre2_lemma = classified_results(predList_pre2_lemma[0], predList_pre2_lemma[1], predList_pre2_lemma[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize accuracy and recall list \n",
    "acc_list, f1score_list, recall_list = [], [], []\n",
    "\n",
    "# Classify df_pre1\n",
    "predList_pre1 = classify_data(train_pre1, test_pre1, 0)\n",
    "eval_pre1 = find_evaluation(predList_pre1[1], predList_pre1[2])\n",
    "\n",
    "# Classify df_pre2\n",
    "predList_pre2 = classify_data(train_pre2, test_pre2, 0)\n",
    "eval_pre2 = find_evaluation(predList_pre2[1], predList_pre2[2])\n",
    "\n",
    "# ==== Stemmed and Lemma dataset  ====\n",
    "# Classify df_pre1_stemmed\n",
    "predList_pre1_stemmed = classify_data(train_pre1_stemmed, test_pre1_stemmed, 0)\n",
    "eval_pre1_stemmed = find_evaluation(predList_pre1_stemmed[1], predList_pre1_stemmed[2])\n",
    "\n",
    "# Classify df_pre1_lemma\n",
    "predList_pre1_lemma = classify_data(train_pre1_lemma, test_pre1_lemma, 0)\n",
    "eval_pre1_lemma = find_evaluation(predList_pre1_lemma[1], predList_pre1_lemma[2])\n",
    "\n",
    "# Classify df_pre2_stemmed\n",
    "predList_pre2_stemmed = classify_data(train_pre2_stemmed, test_pre2_stemmed, 0)\n",
    "eval_pre2_stemmed = find_evaluation(predList_pre2_stemmed[1], predList_pre2_stemmed[2])\n",
    "\n",
    "# Classify df_pre2_lemma\n",
    "predList_pre2_lemma = classify_data(train_pre2_lemma, test_pre2_lemma, 0)\n",
    "eval_pre2_lemma = find_evaluation(predList_pre2_lemma[1], predList_pre2_lemma[2])\n",
    "\n",
    "# Assign all variables into all_eval list\n",
    "all_eval = [\n",
    "    eval_pre1, eval_pre2,\n",
    "    eval_pre1_stemmed, eval_pre1_lemma,\n",
    "    eval_pre2_stemmed, eval_pre2_lemma\n",
    "]\n",
    "\n",
    "# Get accuracy and recall and assign those into the respective list\n",
    "acc_list = [round(x[0]*100,2) for x in all_eval]\n",
    "f1score_list = [round(x[1]*100,2) for x in all_eval]\n",
    "recall_list = [round(x[2]*100,2) for x in all_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy from each datasets\n",
      "\n",
      "Accuracy_pre1 : 73.1\n",
      "Accuracy_pre2 : 82.23\n",
      "Accuracy_pre1_stemmed : 76.65\n",
      "Accuracy_pre1_lemma : 74.11\n",
      "Accuracy_pre2_stemmed : 84.26\n",
      "Accuracy_pre2_lemma : 82.74\n",
      "\n",
      "\n",
      "Model F1_Score from each datasets\n",
      "\n",
      "Recall_pre1 : 80.0\n",
      "Recall_pre2 : 85.83\n",
      "Recall_pre1_stemmed : 82.17\n",
      "Recall_pre1_lemma : 80.61\n",
      "Recall_pre2_stemmed : 87.14\n",
      "Recall_pre2_lemma : 86.07\n",
      "\n",
      "\n",
      "Model Recall from each datasets\n",
      "\n",
      "Recall_pre1 : 100.0\n",
      "Recall_pre2 : 100.0\n",
      "Recall_pre1_stemmed : 100.0\n",
      "Recall_pre1_lemma : 100.0\n",
      "Recall_pre2_stemmed : 99.06\n",
      "Recall_pre2_lemma : 99.06\n"
     ]
    }
   ],
   "source": [
    "# Output accuracy and recall from each dataset\n",
    "nameList = ['_pre1', '_pre2', '_pre1_stemmed', '_pre1_lemma', '_pre2_stemmed', '_pre2_lemma']\n",
    "print(\"Model Accuracy from each datasets\\n\")\n",
    "for i in range (len(all_eval)):\n",
    "    print('Accuracy'+nameList[i],':',acc_list[i])\n",
    "print(\"\\n\")\n",
    "print(\"Model F1_Score from each datasets\\n\")\n",
    "for i in range (len(all_eval)):\n",
    "    print('Recall'+nameList[i],':',f1score_list[i])\n",
    "print(\"\\n\")\n",
    "print(\"Model Recall from each datasets\\n\")\n",
    "for i in range (len(all_eval)):\n",
    "    print('Recall'+nameList[i],':',recall_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export classified results into csv file\n",
    "# rs_lists = [\n",
    "#     rs_pre1, rs_pre2, \n",
    "#     rs_pre1_stemmed, rs_pre1_lemma,\n",
    "#     rs_pre2_stemmed, rs_pre2_lemma,\n",
    "# ]\n",
    "\n",
    "# wc_name= 'wc_'\n",
    "# for i in range(len(rs_lists)):\n",
    "#     export_data(rs_lists[i][1], wc_name+listNama[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find accuracy by tuning smoothing parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define alpha values\n",
    "alpha_arr = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Get accuracy and wrong classified of each dataset -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list to get model accuracy and wrong classified data from df_pre2\n",
    "acc_arr_pre2, f1score_arr_pre2, recall_arr_pre2, wr_classified_pre2 = ([] for i in range(4))\n",
    "\n",
    "# Iterate through alpha list to get each predicted data, classified results and accuracy model of df_pre2\n",
    "for item in alpha_arr:\n",
    "    predList_pre2 = classify_data(train_pre2, test_pre2, item)\n",
    "    rs_pre2 = classified_results(predList_pre2[0], predList_pre2[1], predList_pre2[2])\n",
    "    eval_pre2 = find_evaluation(predList_pre2[1], predList_pre2[2])\n",
    "    \n",
    "    # Append accuracy and wrong classified data into lists\n",
    "    acc_arr_pre2.append(eval_pre2[0])\n",
    "    f1score_arr_pre2.append(eval_pre2[1])\n",
    "    recall_arr_pre2.append(eval_pre2[2])\n",
    "    wr_classified_pre2.append(rs_pre2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy pada data dengan tuning parameter alpha: [80.2, 81.73, 82.74, 84.77, 82.23, 73.1, 53.81, 53.81, 53.81]\n",
      "F1 Score pada data dengan tuning parameter alpha: [84.46, 85.48, 86.07, 87.39, 85.83, 80.0, 69.97, 69.97, 69.97]\n",
      "Recall pada data dengan tuning parameter alpha: [100.0, 100.0, 99.06, 98.11, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy pada data dengan tuning parameter alpha:\", [round(x*100, 2) for x in acc_arr_pre2])\n",
    "print(\"F1 Score pada data dengan tuning parameter alpha:\", [round(x*100, 2) for x in f1score_arr_pre2])\n",
    "print(\"Recall pada data dengan tuning parameter alpha:\", [round(x*100, 2) for x in recall_arr_pre2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Output lists accuracy of df_pre1 & df_pre2 with respective alpha --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha dengan akurasi maksimum : 0.1\n"
     ]
    }
   ],
   "source": [
    "# Get max index of accuracy list and match into alpha list\n",
    "max_idx_pre2 = acc_arr_pre2.index(max(acc_arr_pre2))\n",
    "\n",
    "# Show which alpha that yields max accuracy\n",
    "print(\"Alpha dengan akurasi maksimum :\", alpha_arr[max_idx_pre2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Show how many wrong classified data from each alpha value --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Banyak masing masing wrong_classified pada pre2:\n",
      "Alpha 0.0001 : 39\n",
      "Alpha 0.001 : 36\n",
      "Alpha 0.01 : 34\n",
      "Alpha 0.1 : 30\n",
      "Alpha 1 : 35\n",
      "Alpha 10 : 53\n",
      "Alpha 100 : 91\n",
      "Alpha 1000 : 91\n",
      "Alpha 10000 : 91\n"
     ]
    }
   ],
   "source": [
    "# Wrong classified data from df_pre2\n",
    "print(\"\\nBanyak masing masing wrong_classified pada pre2:\")\n",
    "for i in range(len(wr_classified_pre2)):\n",
    "    print(\"Alpha\",alpha_arr[i],\":\",len(wr_classified_pre2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export wrong classified data from each dataset into csv file\n",
    "# for i in range(len(wr_classified_pre1)):\n",
    "#     export_data(wr_classified_pre1[i], 'wc_pre1_'+str(i))\n",
    "#     export_data(wr_classified_pre2[i], 'wc_pre2_'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Alpha dan Misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Run Functions --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract words feature from dataset\n",
    "def ext_feature(dataset):\n",
    "    tokens = dataset.text.apply(lambda x: x.split())\n",
    "    words_df = pd.DataFrame(pd.Series([w for ws in list(tokens) for w in ws]).value_counts())\n",
    "    words_df.reset_index(inplace=True)\n",
    "    words_df.sort_values(by='index', inplace=True)\n",
    "    words_df.reset_index(drop=True, inplace=True)\n",
    "    words_df.rename(columns={'index':'word', 0:'freq'}, inplace=True)\n",
    "    return words_df\n",
    "\n",
    "# Create dataframe containing words from each data labels without duplicate words\n",
    "def get_all_w(dep_word, nonDep_word):\n",
    "    all_words = list(set(list(dep_word.word) + list(nonDep_word.word)))\n",
    "    all_words = pd.DataFrame(all_words, columns=['word']).sort_values(by='word')\n",
    "    all_words.reset_index(drop=True, inplace=True)\n",
    "    return all_words\n",
    "\n",
    "# Create dataframe containing words feature with frequency on each labels\n",
    "def ext_final_ft(dataset):\n",
    "    data_dep = ext_feature(dataset[dataset.label == 1])\n",
    "    data_nonDep = ext_feature(dataset[dataset.label == 0])\n",
    "    \n",
    "    all_words = get_all_w(data_dep, data_nonDep)\n",
    "    all_words['freq_dep'] = 0\n",
    "    all_words['freq_nonDep'] = 0\n",
    "\n",
    "    # Ambil index setiap feature dep dan non dep\n",
    "    dep_idx = list(all_words[all_words.word.isin(list(data_dep.word))].index)\n",
    "    nonDep_idx = list(all_words[all_words.word.isin(list(data_nonDep.word))].index)\n",
    "\n",
    "    all_words.loc[dep_idx, 'freq_dep'] = list(data_dep.freq)\n",
    "    all_words.loc[nonDep_idx, 'freq_nonDep'] = list(data_nonDep.freq)\n",
    "    \n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Show info of wrong classified data --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Variable info:</h4><br>\n",
    "1. wr_to_right: wrong classified data into right classified after change of alpha<br>\n",
    "2. still_wrong: wrong classified data still in wrong classified after change of alpha<br>\n",
    "3. new_wrong: newly wrong classified data after change of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Keterangan pada df_pre2 =========\n",
      "Banyak wr_classified dengan alpha=1: 35\n",
      "Banyak wr_classified dengan alpha=0.1: 30\n",
      "\n",
      "Banyak data yang menjadi benar: 11\n",
      "Banyak data yang tetap salah: 24\n",
      "Banyak data salah yang baru muncul: 6\n"
     ]
    }
   ],
   "source": [
    "# wr_to_right_pre2\n",
    "print(\"========= Keterangan pada df_pre2 =========\")\n",
    "print(\"Banyak wr_classified dengan alpha=1:\", len(wr_classified_pre2[4]))\n",
    "print(\"Banyak wr_classified dengan alpha=0.1:\", len(wr_classified_pre2[3]))\n",
    "\n",
    "# Get each wrong classified from df_pre2\n",
    "wr_to_right_pre2 = [x for x in list(wr_classified_pre2[4].text) if x not in list(wr_classified_pre2[3].text)]\n",
    "still_wrong_pre2 = [x for x in list(wr_classified_pre2[4].text) if x in list(wr_classified_pre2[3].text)]\n",
    "new_wrong_pre2 = [x for x in list(wr_classified_pre2[3].text) if x not in list(wr_classified_pre2[4].text)]\n",
    "\n",
    "print(\"\\nBanyak data yang menjadi benar:\", len(wr_to_right_pre2))\n",
    "print(\"Banyak data yang tetap salah:\", len(still_wrong_pre2))\n",
    "print(\"Banyak data salah yang baru muncul:\", len(new_wrong_pre2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset location\n",
    "folder = 'D:/College Stuff/Implementasi TA/new_dataset/tfidf_features/'\n",
    "\n",
    "# Import each feature of df_pre1&df_pre2\n",
    "fitur_pre2 = import_data(folder, 'pre2/fitur_pre2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Get out-of-vocab (oov) from each test data --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Banyak out-of-vocab dari data test_pre2: 815\n",
      "Percentage of oov of the overall vocab: 0.38048552754435105\n"
     ]
    }
   ],
   "source": [
    "# Extract words feature from each test data\n",
    "voc_test_pre2 = ext_final_ft(test_pre2)\n",
    "\n",
    "# Get out-of-vocab words from each test data\n",
    "oov_pre2 = [x for x in list(voc_test_pre2.word) if x not in list(fitur_pre2.feature)]\n",
    "\n",
    "# Show info of oov from each test dataset\n",
    "# df_pre2-info\n",
    "print(\"\\nBanyak out-of-vocab dari data test_pre2:\", len(oov_pre2))\n",
    "print(\"Percentage of oov of the overall vocab:\", len(oov_pre2) / len(voc_test_pre2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq_dep</th>\n",
       "      <th>freq_nonDep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>abilities</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>abortion</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>abt</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  freq_dep  freq_nonDep\n",
       "0  abilities         0            1\n",
       "1   abortion         1            0\n",
       "2        abt         0            1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe of each \n",
    "oov_pre2 = voc_test_pre2[voc_test_pre2.word.isin(oov_pre2)].reset_index(drop=True)\n",
    "oov_pre2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print oov info for each label of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Banyak oov_pre2 yang muncul pada data depresi 524\n",
      "Banyak oov_pre2 yang muncul pada data non-depresi 312\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBanyak oov_pre2 yang muncul pada data depresi\",len(oov_pre2[oov_pre2.freq_dep > 0]))\n",
    "print(\"Banyak oov_pre2 yang muncul pada data non-depresi\",len(oov_pre2[oov_pre2.freq_nonDep > 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the wrong_classification before change of alpha that contains oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract oov from dataset\n",
    "def extract_oov(dataset, oov):\n",
    "    tok_dataset = dataset.text.apply(lambda x: str(x).split())\n",
    "    oov_dataset = tok_dataset.apply(lambda x: [w for w in x if w in list(oov.word)])\n",
    "    dataset['oov'] = list(oov_dataset)\n",
    "    dataset['oov_count'] = dataset.oov.apply(lambda x: len(x))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Show info of how many wrong classified that contains oov -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banyak data yg terklasifikasi salah pada pre2 dengan oov: 30 dari 35\n"
     ]
    }
   ],
   "source": [
    "wr_classified_pre2[4] = extract_oov(wr_classified_pre2[4], oov_pre2) # alpha=1\n",
    "wr_classified_pre2[3] = extract_oov(wr_classified_pre2[3], oov_pre2) # alpha = 0.1\n",
    "\n",
    "# Output info of how many wrong classified data with oov from each datasets\n",
    "print(\"banyak data yg terklasifikasi salah pada pre2 dengan oov:\", \\\n",
    "      len(wr_classified_pre2[4][wr_classified_pre2[4].oov_count > 0]), 'dari', len(wr_classified_pre2[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banyak data yg terklasifikasi salah pada pre1 dengan oov: 27 dari 30\n"
     ]
    }
   ],
   "source": [
    "wr_classified_pre2[4] = extract_oov(wr_classified_pre2[4], oov_pre2) # alpha=1\n",
    "wr_classified_pre2[3] = extract_oov(wr_classified_pre2[3], oov_pre2) # alpha = 0.1\n",
    "\n",
    "# Output info of how many wrong classified data with oov from each datasets\n",
    "print(\"banyak data yg terklasifikasi salah pada pre1 dengan oov:\", \\\n",
    "      len(wr_classified_pre2[3][wr_classified_pre2[3].oov_count > 0]), 'dari', len(wr_classified_pre2[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
